{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "48553db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "71992604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0b888",
   "metadata": {},
   "source": [
    "# Pytorch Dataset wrapper around tfrecords by Huan\n",
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5dd86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_ending_with(folder_or_folders, ext):\n",
    "    if isinstance(folder_or_folders, str):\n",
    "        folder = folder_or_folders\n",
    "        assert os.path.exists(folder)\n",
    "\n",
    "        fnames = []\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.endswith(ext):       \n",
    "                fnames.append(os.path.join(folder, fname))\n",
    "        return sorted(fnames)\n",
    "    else:\n",
    "        assert hasattr(folder_or_folders, '__iter__')\n",
    "        print('folder_or_folders:', folder_or_folders)\n",
    "        return list(itertools.chain(*[get_files_ending_with(folder, ext) for folder in folder_or_folders]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04a2b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def collate_batch(batch):\n",
    "    # image, actions, robot_state, collision_label, info_label, height, width, depth, action_horizon = [], [], [], [], [], [], [], [], []\n",
    "    # for _image, _actions, _robot_state, _collision_label, _info_label, _height, _width, _depth, _action_horizon in batch:\n",
    "    #     image.append(_image.numpy())\n",
    "    #     actions.append(_actions.numpy())\n",
    "    #     robot_state.append(_robot_state.numpy())\n",
    "    #     collision_label.append(_collision_label.numpy())\n",
    "    #     info_label.append(_info_label.numpy())\n",
    "    #     height.append(_height.numpy())\n",
    "    #     width.append(_width.numpy())\n",
    "    #     depth.append(_depth.numpy())\n",
    "    #     action_horizon.append(_action_horizon.numpy())\n",
    "    # print('batch[0]:', batch[0])\n",
    "    image = batch[0][0]\n",
    "    height = batch[0][1]\n",
    "    width = batch[0][2]\n",
    "    depth = batch[0][3]\n",
    "    \n",
    "    return torch.Tensor(np.array(image)).to(device), torch.Tensor(np.array(height)).to(device), torch.Tensor(np.array(width)).to(device), torch.Tensor(np.array(depth)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86599e6f",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "10156a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterableDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, tfrecord_folder):\n",
    "        super(MyIterableDataset).__init__()\n",
    "        self.tfrecord_folder = tfrecord_folder\n",
    "        self.itr = self.load_tfrecords()\n",
    "\n",
    "    def read_tfrecord(self, serialized_example):\n",
    "        feature_description = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "\n",
    "        image = tf.transpose(tf.cast(tf.io.parse_tensor(example['image'], out_type = tf.uint8), tf.float32),  perm=[2, 0, 1])\n",
    "        height = example['height']\n",
    "        width = example['width']\n",
    "        depth = example['depth']\n",
    "        return image, height, width, depth\n",
    "\n",
    "    def load_tfrecords(self, is_shuffle_and_repeat=True, shuffle_buffer_size=5000, prefetch_buffer_size_multiplier=2, batch_size = 32):\n",
    "        print('Loading tfrecords...')\n",
    "        tfrecord_fnames = get_files_ending_with(self.tfrecord_folder, '.tfrecords')\n",
    "        assert len(tfrecord_fnames) > 0\n",
    "        if is_shuffle_and_repeat:\n",
    "            np.random.shuffle(tfrecord_fnames)\n",
    "        else:\n",
    "            tfrecord_fnames = sorted(tfrecord_fnames)\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(tfrecord_fnames)\n",
    "        dataset = dataset.map(self.read_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        if is_shuffle_and_repeat: \n",
    "            dataset = dataset.shuffle(buffer_size=shuffle_buffer_size, reshuffle_each_iteration=True)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(buffer_size=prefetch_buffer_size_multiplier * batch_size)\n",
    "\n",
    "        iterator = dataset.__iter__()\n",
    "        print('Done.')\n",
    "        return iterator\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.itr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98fb9b",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0020da68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tfrecords...\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MyIterableDataset.read_tfrecord of <__main__.MyIterableDataset object at 0x7f2cae7acd90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MyIterableDataset.read_tfrecord of <__main__.MyIterableDataset object at 0x7f2cae7acd90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dataset = MyIterableDataset('../../../rl_data/tfrecord')\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7f33a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "16fd79e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = data[0]\n",
    "img_idx = 20\n",
    "io.imshow(image[img_idx,0,...].numpy())\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ddfd7ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 270, 480, 1]),\n",
       " torch.Size([32]),\n",
       " torch.Size([32]),\n",
       " torch.Size([32]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, height, width, depth = data\n",
    "image.shape, height.shape, width.shape, depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dcaf2a8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 : <class 'torch.Tensor'>\n",
      "99 : <class 'torch.Tensor'>\n",
      "149 : <class 'torch.Tensor'>\n",
      "199 : <class 'torch.Tensor'>\n",
      "249 : <class 'torch.Tensor'>\n",
      "299 : <class 'torch.Tensor'>\n",
      "349 : <class 'torch.Tensor'>\n",
      "399 : <class 'torch.Tensor'>\n",
      "449 : <class 'torch.Tensor'>\n",
      "499 : <class 'torch.Tensor'>\n",
      "549 : <class 'torch.Tensor'>\n",
      "599 : <class 'torch.Tensor'>\n",
      "649 : <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for image, height, width, depth in loader:\n",
    "    i += 1\n",
    "    if (i+1) % 50 == 0:\n",
    "        print(i, \":\", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcc4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
