{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4b6ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 11:18:03.973616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/home/patricknit/.mujoco/mjpro150/bin\n",
      "2022-03-08 11:18:03.973638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/patricknit/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "import cv2\n",
    "\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0311c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RANGE = 10.0 # max range of depth image [m]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "215ee388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    io.imshow(image, cmap=\"gray\")\n",
    "    io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce89173",
   "metadata": {},
   "source": [
    "# Write TFrecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a6acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_folders = \"/home/patricknit/rl_data\"\n",
    "load_paths = [os.path.join(saves_folders, saves_folder) for saves_folder in os.listdir(saves_folders)]\n",
    "\n",
    "load_path = \"/home/patricknit/rl_data/saves_1\"\n",
    "save_path = \"/home/patricknit/rl_data/tfrecord_wfiltered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43e71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(image, image_filtered, image_shape):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'image_filtered': _bytes_feature(image_filtered),\n",
    "        'height': _int64_feature(image_shape[1]),\n",
    "        'width': _int64_feature(image_shape[2]),\n",
    "        'depth': _int64_feature(image_shape[0])\n",
    "    }\n",
    "    #  Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF PICKLE STACKS 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 11:18:05.277085: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-08 11:18:05.277105: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (patricknit-OptiPlex-7060): /proc/driver/nvidia/version does not exist\n",
      "2022-03-08 11:18:05.277288: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "DI_SHAPE = (1, 270, 480)\n",
    "nb_files = int(len([f for f in os.listdir(load_path) if f.endswith('.p') and os.path.isfile(os.path.join(load_path, f))])) # one dicts\n",
    "print(\"NUMBER OF PICKLE STACKS\", nb_files)\n",
    "for k in range(nb_files):\n",
    "    di_load = pickle.load(open( load_path + \"/di_dump\" + str(k) + \".p\", \"rb\"))\n",
    "\n",
    "    filename = save_path + '/data' + str(k) + '.tfrecords'\n",
    "    N_episode = len(di_load)\n",
    "\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for i in range(N_episode):\n",
    "            di_episode = di_load[i]\n",
    "            N_images = len(di_episode)\n",
    "\n",
    "            N_sample_append = 0\n",
    "            is_first_collide_idx = False\n",
    "            for j in range(N_images):\n",
    "                di_current = np.moveaxis(di_episode[j], source=-1, destination=0)\n",
    "                \n",
    "                # Filtering\n",
    "                di_filtered = utilities.filter_depth_image(np.copy(di_current))\n",
    "\n",
    "#                 imshow(di_current.squeeze())\n",
    "#                 imshow(di_filtered)\n",
    "\n",
    "                example = serialize_example(\n",
    "                    tf.io.serialize_tensor(di_current), tf.io.serialize_tensor(di_filtered), DI_SHAPE\n",
    "                )\n",
    "                writer.write(example)\n",
    "\n",
    "                # flip data along width\n",
    "                di_flip = np.flip(di_current, axis=2)\n",
    "\n",
    "                # io.imshow(di_flip[...,0] / 255)\n",
    "                # io.show()\n",
    "\n",
    "                di_flip_filtered = utilities.filter_depth_image(np.copy(di_flip))\n",
    "                \n",
    "                example_flip = serialize_example(\n",
    "                    tf.io.serialize_tensor(di_flip), tf.io.serialize_tensor(di_flip_filtered), DI_SHAPE\n",
    "                )\n",
    "                writer.write(example_flip)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153f387",
   "metadata": {},
   "source": [
    "# Read TFrecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = \"/home/patricknit/rl_data/tfrecord_wfiltered\"\n",
    "tf_files = os.listdir(tfrecord_path)\n",
    "tf_files_full = [os.path.join(tfrecord_path, file) for file in tf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(tf_files_full)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d8898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for raw_record in raw_dataset.take(1):\n",
    "#     print(repr(raw_record))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
