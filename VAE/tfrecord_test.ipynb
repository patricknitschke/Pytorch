{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tfrecord.torch.dataset import TFRecordDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce89173",
   "metadata": {},
   "source": [
    "# Write TFrecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_folders = \"../../../rl_data\"\n",
    "load_paths = [os.path.join(saves_folders, saves_folder) for saves_folder in os.listdir(saves_folders)]\n",
    "\n",
    "load_path = \"../../../rl_data/saves_1\"\n",
    "save_path = \"../../../rl_data/tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(image, image_shape):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'height': _int64_feature(image_shape[0]),\n",
    "        'width': _int64_feature(image_shape[1]),\n",
    "        'depth': _int64_feature(image_shape[2]),\n",
    "    }\n",
    "    #  Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DI_SHAPE = (270, 480, 1)\n",
    "nb_files = int(len([f for f in os.listdir(load_path) if f.endswith('.p') and os.path.isfile(os.path.join(load_path, f))]) / 5) # five dicts\n",
    "print(\"NUMBER OF PICKLE STACKS\", nb_files)\n",
    "for k in range(nb_files):\n",
    "    obs_load          = pickle.load(open( load_path + \"/obs_dump\" +str(k) + \".p\", \"rb\"))\n",
    "    di_load           = pickle.load(open( load_path + \"/di_dump\" + str(k) + \".p\", \"rb\"))\n",
    "    action_load       = pickle.load(open( load_path + \"/action_dump\" + str(k) + \".p\", \"rb\"))\n",
    "    action_index_load = pickle.load(open( load_path + \"/action_index_dump\" + str(k) + \".p\", \"rb\"))\n",
    "    collision_load    = pickle.load(open( load_path + \"/collision_dump\" + str(k) + \".p\", \"rb\"))\n",
    "\n",
    "    filename = save_path + '/data' + str(k) + '.tfrecords'\n",
    "    N_episode = len(di_load)\n",
    "\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for i in range(N_episode):\n",
    "            di_episode = di_load[i]\n",
    "            N_images = len(di_episode)\n",
    "\n",
    "            N_sample_append = 0\n",
    "            is_first_collide_idx = False\n",
    "            for j in range(N_images):\n",
    "                di_current = di_episode[j]\n",
    "\n",
    "                example = serialize_example(tf.io.serialize_tensor(di_current), DI_SHAPE)\n",
    "                writer.write(example)\n",
    "\n",
    "                # augment horizontally flip data\n",
    "                # io.imshow(di_current[...,0] / 255)\n",
    "                # io.show()\n",
    "                di_flip = np.flip(di_current, 1)\n",
    "\n",
    "                # io.imshow(di_flip[...,0] / 255)\n",
    "                # io.show()\n",
    "\n",
    "                # flip the omega_z # TODO what about other states?\n",
    "                example_flip = serialize_example(tf.io.serialize_tensor(di_flip), DI_SHAPE)\n",
    "                writer.write(example_flip)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153f387",
   "metadata": {},
   "source": [
    "# Read TFrecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = \"../../../rl_data/tfrecord\"\n",
    "tf_files = os.listdir(tfrecord_path)\n",
    "tf_files_full = [os.path.join(tfrecord_path, file) for file in tf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(tf_files_full)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_record in raw_dataset.take(1):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = tf_files_full[0]\n",
    "index_path = None\n",
    "import cv2\n",
    "\n",
    "description = {\n",
    "    \"image\": \"byte\", \n",
    "    \"height\": \"int\",\n",
    "    \"width\": \"int\",\n",
    "    \"depth\": \"int\"\n",
    "}\n",
    "\n",
    "def decode_image(features):\n",
    "    # get BGR image from bytes\n",
    "    features[\"image\"] = cv2.imdecode(features[\"image\"], -1)\n",
    "    return features\n",
    "\n",
    "dataset = TFRecordDataset(tfrecord_path, index_path=None, description=description)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "\n",
    "data = next(iter(loader))\n",
    "for i in range(32):\n",
    "    print(data[\"image\"][i].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
